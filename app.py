
from pywebio import start_server
import pywebio.input as webin
import pywebio.output as webout
from pywebio.session import info as session_info
import base64
import json
from PIL import Image
import io

from keras.models import load_model
model = load_model('model100.h5')

from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

import numpy as np
import matplotlib.pyplot as plt
import cv2

import spot as sp

def emotion_analysis(emotions):
    objects = ('Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral')
    y_pos = np.arange(len(objects))

    plt.bar(y_pos, emotions, align='center', alpha=0.5)
    plt.xticks(y_pos, objects)
    plt.ylabel('percentage')
    plt.title('emotion')
    plt.savefig('graph.png')

    res=(max(emotions))
    j=0
    for i in emotions:
      if(i==res) : break
      else : j=j+1

    Emotion=str(objects[j])
    accuracy = str(res*100)

    print('Emotion Detected : ' + Emotion)
    print('Accuracy : '+ str(res*100))

    return Emotion, accuracy

def facecrop(image):

    image = image[23:]
    facedata = "haarcascade_frontalface_default.xml"
    cascade = cv2.CascadeClassifier(facedata)

    img_b64decode = base64.b64decode(image) # base64 decoding

    img_array = np.fromstring(img_b64decode,np.uint8) # convert np sequence
    img=cv2.imdecode(img_array,cv2.COLOR_BGR2RGB) # Convert Opencv format

    try:

        minisize = (img.shape[1],img.shape[0])
        miniframe = cv2.resize(img, minisize)

        faces = cascade.detectMultiScale(miniframe)
        print(faces)
        for f in faces:
            x, y, w, h = [ v for v in f ]
            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)

            sub_face = img[y:y+h, x:x+w]


            cv2.imwrite('capture.jpg', sub_face)
            #print ("Writing: " + image)

    except Exception as e:
        print (e)


def main():
    webout.put_html("<center style='font-size: 40px;font-weight:bold;margin-bottom: 50px;'>Generating Playlist Using Facial Expression</center>")
    data = webin.file_upload("Select a image:", accept="image/*")
    data = data['content']

    # print(data)

    # img = json.loads(info)['dataurl']
    # webout.put_image(data)

    facecrop(data)

    file = 'capture.jpg'
    true_image = image.load_img(file)
    img = image.load_img(file, grayscale=True, target_size=(48, 48))

    x = image.img_to_array(img)
    x = np.expand_dims(x, axis = 0)

    x /= 255

    custom = model.predict(x)

    final_Emotion, final_Accuracy=emotion_analysis(custom[0])

    html = ""
    # webout.put_image(open('graph.png' , 'rb').read())
    blob_img = None
    with open("graph.png", "rb") as fh:
        blob_img = base64.b64encode(fh.read()).decode()

    # print(str(data))

    img_html = "<center> <h4 style='font-size:30px;font-weight:bold'>Output: </h4> <br/> <br/> <img src='data:image/png;base64,"+str(blob_img)+"' style='height:350px;width:45%;box-shadow: 10px 10px 5px grey;' /></center><br/><br/><br/>"
    # img_html = "<img src='"+current_directory+"\\graph.png' />"
    html += img_html

    # print(custom[0])

    emotion_html = "<center style='font-size:20px;font-weight:bold'>Emotion Detected: " + final_Emotion + "<br />Accuracy : "+ final_Accuracy +"</center><br />"
    html += emotion_html


    final_list = sp.songs_by_emotion(final_Emotion)

    playlist_html = ""

    playlist_html += '<center><br/>----------------------------------------------------------------------------------------------------<br />'

    playlist_html += "<h2 style='font-weight:bold'>PLAYLISTS GENERATED BY USING THE EMOTION : " + final_Emotion.upper() + "</h2>"

    playlist_html +='-----------------------------------------------------------------------------------------------------------------------<br /><center>'

    currentPlaylist = 0


    for el in final_list:
        currentPlaylist += 1

        playlist_html+= "<h2 style='text-align:center;'>PLAYLIST - " +str(currentPlaylist)+ ":</h2>"

        playlist_html+= "<table style='width:80%;padding: 10px;border: 1px solid black;border-collapse: collapse;box-shadow: 10px 10px 5px grey;'>"
        playlist_html+= "<tr>"
        playlist_html+= "<th style='width:8%;text-align:center;border: 1px solid black;border-collapse: collapse;padding: 10px;'><h4>S.no</h4></th>"
        playlist_html+= "<th style='width:92%;text-align:center;border: 1px solid black;border-collapse: collapse;padding: 10px;'><h4>Songs</h4></th>"
        playlist_html+= "</tr>"

        for i in range(0,len(el['playlist_songs'])):

            playlist_html+= "<tr>"
            playlist_html+= "<td style='width:8%;text-align:center;border: 1px solid black;border-collapse: collapse;padding: 10px;'>" + str(i+1) + '. ' "</td>"
            playlist_html+= "<td style='width:92%;text-align:center;border: 1px solid black;border-collapse: collapse;padding: 10px;'>" + el['playlist_songs'][i] + "</td>"
            playlist_html+= "</tr>"

        playlist_html+= "</table>"


    # for el in final_list:
    #     currentPlaylist += 1
    #     playlist_html += 'Playlist - '+str(currentPlaylist)+':<br />'
    #     for i in range(0,len(el['playlist_songs'])):
    #         playlist_html += str(i+1) + ') ' + el['playlist_songs'][i] + "<br />"
    #     playlist_html += "<br/>"

    html += playlist_html
    webout.put_html(html)


if __name__ == '__main__':
    start_server(main, debug=True, port=4002, cdn=False)
